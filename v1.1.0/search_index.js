var documenterSearchIndex = {"docs":
[{"location":"lapack.html#BLAS-and-LAPACK-reference","page":"BLAS and LAPACK reference","title":"BLAS and LAPACK reference","text":"","category":"section"},{"location":"lapack.html","page":"BLAS and LAPACK reference","title":"BLAS and LAPACK reference","text":"StandardPacked.jl makes several BLAS and LAPACK functions related to packed matrices available that are not provided by Base.","category":"page"},{"location":"lapack.html","page":"BLAS and LAPACK reference","title":"BLAS and LAPACK reference","text":"note: Coverage\nThe general rule of thumb is: Whenever a function is provided in Base for general matrices, this package makes its packed counterpart available. Note that there are a lot of additional BLAS and LAPACK functions with respect to packed matrices for which no interface is provided because the corresponding general function is not made available in Base.If you want to have one of these functions included, just open an issue or pull request.","category":"page"},{"location":"lapack.html","page":"BLAS and LAPACK reference","title":"BLAS and LAPACK reference","text":"warning: Naming\nIt is sometimes rather mysterious why a function has the s (for symmetric) or h (for Hermitian) prefix: for example,spr! is the symmetric rank-1 update, and since it is also implemented (though not made available in Base) for symmetric complex-valued matrices, there is a separate instance hpr! that does the Hermitian equivalent.\nspev! is the symmetric or Hermitian eigensolver (depending on the type), and it does not change its name to hpev! even though LAPACK does. There is no symmetric complex eigensolver.\nhptrd! is the Hermitian or symmetric tridiagonalized (depending on the type), and it does not change its name to sptrd! even though LAPACK does.This mystery comes from following Base's convention of names.","category":"page"},{"location":"lapack.html","page":"BLAS and LAPACK reference","title":"BLAS and LAPACK reference","text":"note: Variants\nNote that for every function, this package provides an undocumented \"raw\" variant that does almost no checking apart from whether the uplo parameter is correct plus a check of the return value. This raw version is usually not made available directly by the Julia Base.Additionally, StandardPacked.jl provide a convenience wrapper that works with the AbstractArray interface, automatically infers dimensions and checks for the compatibility of all the sizes - this is what is commonly provided by Julia. And finally, the vector representing the packed matrix can also be replaced by a SPMatrixUnscaled - then, the uplo argument is not present, as it is determined from the type.","category":"page"},{"location":"lapack.html","page":"BLAS and LAPACK reference","title":"BLAS and LAPACK reference","text":"tip: Performance\nEven the convenience wrappers give more control than you might be used to. Whenever some allocations might occur due to the need for temporaries or additional output arrays, these wrappers will allow to pass preallocated arrays if they are sized appropriately (where output arguments must match exactly in size, but temporaries may also be larger than necessary).Whenever a parameter is documented with a missing default, this is such a parameter that might be preallocated if necessary. The parameters are all passed by position, not by keyword, which allows Julia to remove unnecessary checks by compiling the correct version.","category":"page"},{"location":"lapack.html#BLAS-Level-2","page":"BLAS and LAPACK reference","title":"BLAS Level 2","text":"","category":"section"},{"location":"lapack.html","page":"BLAS and LAPACK reference","title":"BLAS and LAPACK reference","text":"Some of these functions are already present in Base.BLAS and are re-exported in StandardPacked. They are listed here for completeness only.","category":"page"},{"location":"lapack.html#LinearAlgebra.BLAS.spmv!","page":"BLAS and LAPACK reference","title":"LinearAlgebra.BLAS.spmv!","text":"spmv!(α, AP::SPMatrixUnscaled, x, β)\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#LinearAlgebra.BLAS.hpmv!","page":"BLAS and LAPACK reference","title":"LinearAlgebra.BLAS.hpmv!","text":"hpmv!(α, AP::SPMatrixUnscaled, x, β, y)\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#LinearAlgebra.BLAS.spr!","page":"BLAS and LAPACK reference","title":"LinearAlgebra.BLAS.spr!","text":"spr!(α, x, AP::SPMatrix)\n\nwarning: Scaled matrices\nThe variant of this function that takes a SPMatrix also allows for scaled packed matrices. It will automatically call packed_unscale! on the matrix and return the unscaled result. Do not use the reference to the scaled matrix any more, only the result of this function!\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#StandardPacked.hpr!","page":"BLAS and LAPACK reference","title":"StandardPacked.hpr!","text":"hpr!(uplo, α, x, AP::AbstractVector)\nhpr!(α, x, AP::SPMatrix)\n\nUpdate matrix A as A + alpha x x, where A is a Hermitian matrix provided in packed format AP and x is a vector.\n\nWith uplo = 'U', the vector AP must contain the upper triangular part of the Hermitian matrix packed sequentially, column by column, so that AP[1] contains A[1, 1], AP[2] and AP[3] contain A[1, 2] and A[2, 2] respectively, and so on.\n\nWith uplo = 'L', the vector AP must contain the lower triangular part of the symmetric matrix packed sequentially, column by column, so that AP[1] contains A[1, 1], AP[2] and AP[3] contain A[2, 1] and A[3, 1] respectively, and so on.\n\nThe scalar input α must be real.\n\nThe array inputs x and AP must all be of ComplexF32 or ComplexF64 type. Return the updated AP.\n\nwarning: Scaled matrices\nThe variant of this function that takes a SPMatrix also allows for scaled packed matrices. It will automatically call packed_unscale! on the matrix and return the unscaled result. Do not use the reference to the scaled matrix any more, only the result of this function!\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#BLAS-Level-3","page":"BLAS and LAPACK reference","title":"BLAS Level 3","text":"","category":"section"},{"location":"lapack.html#StandardPacked.gemmt!","page":"BLAS and LAPACK reference","title":"StandardPacked.gemmt!","text":"gemmt!(uplo, transA, transB, alpha, A, B, beta, C)\n\ngemmt! computes a matrix-matrix product with general matrices but updates only the upper or lower triangular part of the result matrix.\n\ninfo: Info\nThis function is a recent BLAS extension; for OpenBLAS, it requires at least version 0.3.22 (which is not yet shipped with Julia). If the currently available BLAS does not offer gemmt, the function falls back to gemm.\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#LAPACK","page":"BLAS and LAPACK reference","title":"LAPACK","text":"","category":"section"},{"location":"lapack.html#Conversion","page":"BLAS and LAPACK reference","title":"Conversion","text":"","category":"section"},{"location":"lapack.html#StandardPacked.trttp!","page":"BLAS and LAPACK reference","title":"StandardPacked.trttp!","text":"trttp!(uplo, A, AP::AbstractVector)\ntrttp!(A, AP::SPMatrixUnscaled)\n\ntrttp! copies a triangular matrix from the standard full format (TR) to the standard packed format (TP).\n\ninfo: Info\nThis function is also implemented in plain Julia and therefore works with arbitrary element types.\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#StandardPacked.tpttr!","page":"BLAS and LAPACK reference","title":"StandardPacked.tpttr!","text":"tpttr!(uplo, AP::AbstractVector, A)\ntpttr!(AP::SPMatrixUnscaled, A)\n\ntpttr! copies a triangular matrix from the standard packed format (TP) to the standard full format (TR).\n\ninfo: Info\nThis function is also implemented in plain Julia and therefore works with arbitrary element types.\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#Linear-systems-Cholesky","page":"BLAS and LAPACK reference","title":"Linear systems - Cholesky","text":"","category":"section"},{"location":"lapack.html#StandardPacked.pptrf!","page":"BLAS and LAPACK reference","title":"StandardPacked.pptrf!","text":"pptrf!(uplo, AP::AbstractVector) -> (AP, info)\npptrf!(AP::SPMatrix) -> (AP, info)\n\npptrf! computes the Cholesky factorization of a real symmetric or complex Hermitian positive definite matrix A stored in packed format AP.\n\nThe factorization has the form\n\nA = U U,  if uplo == 'U', or\nA = L L,  if uplo == 'L',\n\nwhere U is an upper triangular matrix and L is lower triangular.\n\nIf info > 0, the leading minor of order info is not positive definite, and the factorization could not be completed.\n\nwarning: Scaled matrices\nThe variant of this function that takes a SPMatrix also allows for scaled packed matrices. It will automatically call packed_unscale! on the matrix and return the unscaled result. Do not use the reference to the scaled matrix any more, only the result of this function!\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#StandardPacked.pptrs!","page":"BLAS and LAPACK reference","title":"StandardPacked.pptrs!","text":"pptrs!(uplo, AP::AbstractVector, B)\npptrs!(AP::SPMatrixUnscaled, B)\n\npptrs! solves a system of linear equations A X = B with a symmetric or Hermitian positive definite matrix A in packed storage AP using the Cholesky factorization A = U U or A = L L computed by pptrf!.\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#StandardPacked.pptri!","page":"BLAS and LAPACK reference","title":"StandardPacked.pptri!","text":"pptri!(uplo, AP::AbstractVector)\npptri!(AP::SPMatrixUnscaled)\n\npptri! computes the inverse of a real symmetric or complex Hermitian positive definite matrix A using the Cholesky factorization A = U U or A = L L computed by pptrf!.\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#Linear-systems-symmetric-indefinite","page":"BLAS and LAPACK reference","title":"Linear systems - symmetric indefinite","text":"","category":"section"},{"location":"lapack.html#StandardPacked.spsv!","page":"BLAS and LAPACK reference","title":"StandardPacked.spsv!","text":"spsv!(uplo, AP::AbstractVector, ipiv=missing, B) -> (B, AP, ipiv)\nspsv!(AP::SPMatrix, ipiv=missing, B) -> (B, AP, ipiv)\n\nspsv! computes the solution to a real or complex system of linear equations A X = B, where A is an N-by-N symmetric matrix stored in packed format AP and X and B are N-by-N_mathrmrhs matrices.\n\nThe diagonal pivoting method is used to factor A as\n\nA = U D U^top,  if UPLO = 'U', or\nA = L D L^top,  if UPLO = 'L',\n\nwhere U (or L) is a product of permutation and unit upper (lower) triangular matrices, D is symmetric and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. The factored form of A is then used to solve the system of equations A X = B.\n\nwarning: Scaled matrices\nThe variant of this function that takes a SPMatrix also allows for scaled packed matrices. It will automatically call packed_unscale! on the matrix and return the unscaled result. Do not use the reference to the scaled matrix any more, only the result of this function!\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#StandardPacked.hpsv!","page":"BLAS and LAPACK reference","title":"StandardPacked.hpsv!","text":"hpsv!(uplo, AP::AbstractVector, ipiv=missing, B) -> (B, AP, ipiv)\nhpsv!(AP::SPMatrix, ipiv=missing, B) -> (B, AP, ipiv)\n\nhpsv! computes the solution to a complex system of linear equations A X = B, where A is an N-by-N Hermitian matrix stored in packed format AP and X and B are N-by-N_mathrmrhs matrices.\n\nThe diagonal pivoting method is used to factor A as\n\nA = U D U,  if UPLO = 'U', or\nA = L D L,  if UPLO = 'L',\n\nwhere U (or L) is a product of permutation and unit upper (lower) triangular matrices, D is Hermitian and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. The factored form of A is then used to solve the system of equations A X = B.\n\nwarning: Scaled matrices\nThe variant of this function that takes a SPMatrix also allows for scaled packed matrices. It will automatically call packed_unscale! on the matrix and return the unscaled result. Do not use the reference to the scaled matrix any more, only the result of this function!\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#StandardPacked.sptrf!","page":"BLAS and LAPACK reference","title":"StandardPacked.sptrf!","text":"sptrf!(uplo, AP::AbstractVector, ipiv=missing) -> (AP, ipiv, info)\nsptrf!(AP::SPMatrix, ipiv=missing) -> (AP, ipiv, info)\n\nsptrf! computes the factorization of a real or complex symmetric matrix A stored in packed format AP using the Bunch-Kaufman diagonal pivoting method:\n\nA = U D U^top  or  A = L D L^top\n\nwhere U (or L) is a product of permutation and unit upper (lower) triangular matrices, and D is symmetric and block diagonal with 1-by-1 and 2-by-2 diagonal blocks.\n\nwarning: Scaled matrices\nThe variant of this function that takes a SPMatrix also allows for scaled packed matrices. It will automatically call packed_unscale! on the matrix and return the unscaled result. Do not use the reference to the scaled matrix any more, only the result of this function!\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#StandardPacked.hptrf!","page":"BLAS and LAPACK reference","title":"StandardPacked.hptrf!","text":"hptrf!(uplo, AP::AbstractVector, ipiv=missing) -> (AP, ipiv, info)\nhptrf!(AP::SPMatrix, ipiv=missing) -> (AP, ipiv, info)\n\nhptrf! computes the factorization of a complex Hermitian matrix A stored in packed format AP using the Bunch-Kaufman diagonal pivoting method:\n\nA = U D U  or  A = L D L\n\nwhere U (or L) is a product of permutation and unit upper (lower) triangular matrices, and D is Hermitian and block diagonal with 1-by-1 and 2-by-2 diagonal blocks.\n\nwarning: Scaled matrices\nThe variant of this function that takes a SPMatrix also allows for scaled packed matrices. It will automatically call packed_unscale! on the matrix and return the unscaled result. Do not use the reference to the scaled matrix any more, only the result of this function!\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#StandardPacked.sptrs!","page":"BLAS and LAPACK reference","title":"StandardPacked.sptrs!","text":"sptrs!(uplo, AP::AbstractVector, ipiv, B)\nsptrs!(AP::SPMatrixUnscaled, ipiv, B)\n\nsptrs! solves a system of linear equations A X = B with a real or complex symmetric matrix A stored in packed format using the factorization A = U D U^top or A = L D L^top computed by sptrf!.\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#StandardPacked.hptrs!","page":"BLAS and LAPACK reference","title":"StandardPacked.hptrs!","text":"hptrs!(uplo, AP::AbstractVector, ipiv, B)\nhptrs!(AP::SPMatrixUnscaled, ipiv, B)\n\nhptrs! solves a system of linear equations A X = B with a complex Hermitian matrix A stored in packed format using the factorization A = U D U or A = L D L computed by hptrf!.\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#StandardPacked.sptri!","page":"BLAS and LAPACK reference","title":"StandardPacked.sptri!","text":"sptri!(uplo, AP::AbstractVector, ipiv, work=missing)\nsptri!(AP::SPMatrixUnscaled, ipiv, work=missing)\n\nsptri! computes the inverse of a real or complex symmetric indefinite matrix A in packed storage AP using the factorization A = U D U^top or A = L D L^top computed by sptrf!.\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#StandardPacked.hptri!","page":"BLAS and LAPACK reference","title":"StandardPacked.hptri!","text":"hptri!(uplo, AP::AbstractVector, ipiv, work=missing)\nhptri!(AP::SPMatrixUnscaled, ipiv, work=missing)\n\nhptri! computes the inverse of a complex Hermitian indefinite matrix A in packed storage AP using the factorization A = U D U or A = L D L computed by hptrf!.\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#Eigenvalue","page":"BLAS and LAPACK reference","title":"Eigenvalue","text":"","category":"section"},{"location":"lapack.html#StandardPacked.spev!","page":"BLAS and LAPACK reference","title":"StandardPacked.spev!","text":"spev!('N', uplo, AP::AbstractVector, W=missing, work=missing[, rwork=missing]) -> W\nspev!('N', AP::SPMatrix, W=missing, work=missing[, rwork=missing]) -> W\nspev!('V', uplo, AP::AbstractVector, W=missing, Z=missing, work=missing\n    [, rwork=missing]) -> (W, Z)\nspev!('V', AP::SPMatrix, W=missing, Z=missing, work=missing[, rwork=missing])\n    -> (W, Z)\n\nFinds the eigenvalues (first parameter 'N') or eigenvalues and eigenvectors (first parameter 'V') of a Hermitian matrix A in packed storage AP. If uplo = 'U', AP is the upper triangle of A. If uplo = 'L', AP is the lower triangle of A.\n\nThe output vector W and matrix Z, as well as the temporaries work and rwork (in the complex case) may be specified to save allocations.\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#StandardPacked.spevx!","page":"BLAS and LAPACK reference","title":"StandardPacked.spevx!","text":"spevx!('N', range, uplo, AP::AbstractVector, vl, vu, il, iu, abstol, W=missing,\n    work=missing[, rwork=missing], iwork=missing) -> view(W)\nspevx!('N', range, AP::SPMatrix, vl, vu, il, iu, abstol, W=missing, work=missing\n    [, rwork=missing], iwork=missing) -> view(W)\nspevx!('V', range, uplo, AP::AbstractVector, vl, vu, il, iu, abstol, W=missing,\n    Z=missing, work=missing[, rwork=missing], iwork=missing, ifail=missing)\n    -> (view(W), view(Z), info, view(ifail))\nspevx!('V', range, AP::SPMatrix, vl, vu, il, iu, abstol, W=missing, Z=missing,\n    work=missing[, rwork=missing], iwork=missing, ifail=missing)\n    -> (view(W), view(Z), info, view(ifail))\n\nFinds the eigenvalues (first parameter 'N') or eigenvalues and eigenvectors (first parameter 'V') of a Hermitian matrix A in packed storage AP. If uplo = 'U', AP is the upper triangle of A. If uplo = 'L', AP is the lower triangle of A. If range = 'A', all the eigenvalues are found. If range = 'V', the eigenvalues in the half-open interval (vl, vu] are found. If range = 'I', the eigenvalues with indices between il and iu are found. abstol can be set as a tolerance for convergence.\n\nThe eigenvalues are returned in W and the eigenvectors in Z. info is zero upon success or the number of eigenvalues that failed to converge; their indices are stored in ifail. The resulting views to the original data are sized according to the number of eigenvalues that fulfilled the bounds given by the range.\n\nThe output vector W, ifail and matrix Z, as well as the temporaries work, rwork (in the complex case), and iwork may be specified to save allocations.\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#StandardPacked.spevd!","page":"BLAS and LAPACK reference","title":"StandardPacked.spevd!","text":"spevd!('N', uplo, AP::AbstractVector, W=missing, work=missing[, rwork=missing],\n    iwork=missing) -> W\nspevd!('N', AP::SPMatrix, W=missing, work=missing[, rwork=missing],\n    iwork=missing) -> W\nspevd!('V', uplo, AP::AbstractVector, W=missing, Z=missing, work=missing\n    [, rwork=missing], iwork=missing) -> (W, Z)\nspevd!('V', AP::SPMatrix, W=missing, Z=missing, work=missing[, rwork=missing],\n    iwork=missing) -> (W, Z)\n\nFinds the eigenvalues (first parameter 'N') or eigenvalues and eigenvectors (first parameter 'V') of a Hermitian matrix A in packed storage AP. If uplo = 'U', AP is the upper triangle of A. If uplo = 'L', AP is the lower triangle of A.\n\nThe output vector W and matrix Z, as well as the temporaries work, rwork (in the complex case), and iwork may be specified to save allocations.\n\nIf eigenvectors are desired, it uses a divide and conquer algorithm.\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#StandardPacked.spgv!","page":"BLAS and LAPACK reference","title":"StandardPacked.spgv!","text":"spgv!(itype, 'N', uplo, AP::AbstractVector, BP::AbstractVector, W=missing,\n    work=missing[, rwork=missing]) -> (W, BP)\nspgv!(itype, 'N', AP::SPMatrix, BP::SPMatrix, W=missing, work=missing\n    [, rwork=missing]) -> (W, BP)\nspgv!(itype, 'V', uplo, AP::AbstractVector, BP::AbstractVector, W=missing, Z=missing,\n    work=missing[, rwork=missing]) -> (W, Z, BP)\nspgv!(itype, 'V', AP::SPMatrix, BP::SPMatrix, W=missing, Z=missing,\n    work=missing[, rwork=missing]) -> (W, Z, BP)\n\nFinds the generalized eigenvalues (second parameter 'N') or eigenvalues and eigenvectors (second parameter 'V') of a Hermitian matrix A in packed storage AP and Hermitian positive-definite matrix B in packed storage BP. If uplo = 'U', AP and BP are the upper triangles of A and B, respectively. If uplo = 'L', they are the lower triangles.\n\nIf itype = 1, the problem to solve is A x = lambda B x.\nIf itype = 2, the problem to solve is A B x = lambda x.\nIf itype = 3, the problem to solve is B A x = lambda x.\n\nOn exit, B is overwritten with the triangular factor U or L from the Cholesky factorization B = U U or B = L L.\n\nThe output vector W and matrix Z, as well as the temporaries work and rwork (in the complex case) may be specified to save allocations.\n\nwarning: Scaled matrices\nThe variant of this function that takes a SPMatrix also allows for scaled packed matrices. It will automatically call packed_unscale! on the matrix and return the unscaled result. Do not use the reference to the scaled matrix any more, only the result of this function!\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#StandardPacked.spgvx!","page":"BLAS and LAPACK reference","title":"StandardPacked.spgvx!","text":"spgvx!(itype, 'N', range, uplo, AP::AbstractVector, BP::AbstractVector, vl, vu,\n    il, iu, abstol, W=missing, work=missing[, rwork=missing], iwork=missing)\n    -> (view(W), BP)\nspgvx!(itype, 'N', range, AP::SPMatrix, BP::SPMatrix, vl, vu, il, iu, abstol,\n    W=missing, work=missing[, rwork=missing], iwork=missing) -> (view(W), BP)\nspgvx!(itype, 'V', range, uplo, AP::AbstractVector, BP::AbstractVector, vl, vu,\n    il, iu, abstol, W=missing, Z=missing, work=missing[, rwork=missing],\n    iwork=missing, ifail=missing) -> (view(W), view(Z), info, view(ifail), BP)\nspgvx!(itype, 'V', range, AP::SPMatrix, BP::SPMatrix, vl, vu, il, iu, abstol,\n    W=missing, Z=missing, work=missing[, rwork=missing], iwork=missing, ifail=missing)\n    -> (view(W), view(Z), info, view(ifail), BP)\n\nFinds the generalized eigenvalues (second parameter 'N') or eigenvalues and eigenvectors (second parameter 'V') of a Hermitian matrix A in packed storage AP and Hermitian positive-definite matrix B in packed storage BP. If uplo = 'U', AP and BP are the upper triangles of A and B, respectively. If uplo = 'L', they are the lower triangles. If range = 'A', all the eigenvalues are found. If range = 'V', the eigenvalues in the half-open interval (vl, vu] are found. If range = 'I', the eigenvalues with indices between il and iu are found. abstol can be set as a tolerance for convergence.\n\nIf itype = 1, the problem to solve is A x = lambda B x.\nIf itype = 2, the problem to solve is A B x = lambda x.\nIf itype = 3, the problem to solve is B A x = lambda x.\n\nOn exit, B is overwritten with the triangular factor U or L from the Cholesky factorization B = U U or B = L L.\n\nThe eigenvalues are returned in W and the eigenvectors in Z. info is zero upon success or the number of eigenvalues that failed to converge; their indices are stored in ifail. The resulting views to the original data are sized according to the number of eigenvalues that fulfilled the bounds given by the range.\n\nThe output vector W, ifail and matrix Z, as well as the temporaries work, rwork (in the complex case), and iwork may be specified to save allocations.\n\nwarning: Scaled matrices\nThe variant of this function that takes a SPMatrix also allows for scaled packed matrices. It will automatically call packed_unscale! on the matrix and return the unscaled result. Do not use the reference to the scaled matrix any more, only the result of this function!\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#StandardPacked.spgvd!","page":"BLAS and LAPACK reference","title":"StandardPacked.spgvd!","text":"spgvd!(itype, 'N', uplo, AP::AbstractVector, BP::AbstractVector, W=missing,\n    work=missing[, rwork=missing], iwork=missing) -> (W, BP)\nspgvd!(itype, 'N', AP::SPMatrix, BP::SPMatrix, W=missing, work=missing\n    [, rwork=missing], iwork=missing) -> (W, BP)\nspgvd!(itype, 'V', uplo, AP::AbstractVector, BP::AbstractVector, W=missing, Z=missing,\n    work=missing[, rwork=missing], iwork=missing) -> (W, Z, BP)\nspgvd!(itype, 'V', AP::SPMatrix, BP::SPMatrix, W=missing, Z=missing,\n    work=missing[, rwork=missing], iwork=missing) -> (W, Z, BP)\n\nFinds the generalized eigenvalues (second parameter 'N') or eigenvalues and eigenvectors (second parameter 'V') of a Hermitian matrix A in packed storage AP and Hermitian positive-definite matrix B in packed storage BP. If uplo = 'U', AP and BP are the upper triangles of A, and B, respectively. If uplo = 'L', they are the lower triangles.\n\nIf itype = 1, the problem to solve is A x = lambda B x.\nIf itype = 2, the problem to solve is A B x = lambda x.\nIf itype = 3, the problem to solve is B A x = lambda x.\n\nOn exit, B is overwritten with the triangular factor U or L from the Cholesky factorization B = U U or B = L L.\n\nThe output vector W and matrix Z, as well as the temporaries work, rwork (in the complex case), and iwork may be specified to save allocations.\n\nIf eigenvectors are desired, it uses a divide and conquer algorithm.\n\nwarning: Scaled matrices\nThe variant of this function that takes a SPMatrix also allows for scaled packed matrices. It will automatically call packed_unscale! on the matrix and return the unscaled result. Do not use the reference to the scaled matrix any more, only the result of this function!\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#Tridiagonal","page":"BLAS and LAPACK reference","title":"Tridiagonal","text":"","category":"section"},{"location":"lapack.html#StandardPacked.hptrd!","page":"BLAS and LAPACK reference","title":"StandardPacked.hptrd!","text":"hptrd!(uplo, AP::AbstractVector, D=missing, E=missing, τ=missing) -> (A, τ, D, E)\nhptrd!(AP::SPMatrix, D=missing, E=missing, τ=missing) -> (A, τ, D, E)\n\nhptrd! reduces a Hermitian matrix A stored in packed form AP to real-symmetric tridiagonal form T by an orthogonal similarity transformation: Q A Q = T. If uplo = 'U', AP is the upper triangle of A, else it is the lower triangle.\n\nOn exit, if uplo = 'U', the diagonal and first superdiagonal of A are overwritten by the corresponding elements of the tridiagonal matrix T, and the elements above the first superdiagonal, with the array τ, represent the orthogonal matrix Q as a product of elementary reflectors. If uplo = 'L' the diagonal and first subdiagonal of A are over-written by the corresponding elements of the tridiagonal matrix T, and the elements below the first subdiagonal, with the array τ, represent the orthogonal matrix Q as a product of elementary reflectors.\n\ntau contains the scalar factors of the elementary reflectors, D contains the diagonal elements of T and E contains the off-diagonal elements of T.\n\nThe output vectors D, E, and τ may be specified to save allocations.\n\nwarning: Scaled matrices\nThe variant of this function that takes a SPMatrix also allows for scaled packed matrices. It will automatically call packed_unscale! on the matrix and return the unscaled result. Do not use the reference to the scaled matrix any more, only the result of this function!\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#StandardPacked.opgtr!","page":"BLAS and LAPACK reference","title":"StandardPacked.opgtr!","text":"opgtr!(uplo, AP::AbstractVector, τ, Q=missing, work=missing)\nopgtr!(AP::SPMatrixUnscaled, τ, Q=missing, work=missing)\n\nExplicitly finds Q, the orthogonal/unitary matrix from hptrd!. uplo, AP, and τ must correspond to the input/output to hptrd!.\n\nThe output matrix Q and the temporary work may be specified to save allocations.\n\n\n\n\n\n","category":"function"},{"location":"lapack.html#StandardPacked.opmtr!","page":"BLAS and LAPACK reference","title":"StandardPacked.opmtr!","text":"opmtr!(side, uplo, trans, AP::AbstractVector, τ, C, work=missing)\nopmtr!(side, trans, AP::SPMatrixUnscaled, τ, C, work=missing)\n\nopmtr! overwrites the general m times n matrix C with\n\n SIDE = 'L' SIDE = 'R'\nTRANS = 'N' Q C C Q\nTRANS = 'T' or 'C' (complex case) Q C C Q\n\nwhere Q is a real orthogonal or complex unitary matrix of order n_q, with n_q = m if SIDE = 'L' and n_q = n if SIDE = 'R'. Q is defined as the product of n_q -1 elementary reflectors, as returned by hptrd! using packed storage:\n\nif UPLO = 'U', Q = H_n_q -1 dotsm H_2 H_1;\nif UPLO = 'L', Q = H_1 H_2 dotsm H_n_q -1.\n\nThe temporary work may be specified to save allocations.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference.html#The-SPMatrix-type","page":"Reference","title":"The SPMatrix type","text":"","category":"section"},{"location":"reference.html#StandardPacked.SPMatrix","page":"Reference","title":"StandardPacked.SPMatrix","text":"SPMatrix{R,V,Fmt}\n\nTwo-dimensional dense Hermitian square matrix in packed storage. Depending on Fmt, we only store the upper or lower triangle in col-major vectorized or scaled vectorized form:\n\n:U: PM[i, j] = PM[i + (j -1) * j ÷ 2] for 1 ≤ i ≤ j ≤ n\n:L: PM[i, j] = PM[i + (j -1) * (2n - j) ÷ 2] for 1 ≤ j ≤ i ≤ n\n:US: PM[i, j] = s(i, j) PM[i + (j -1) * j ÷ 2] for 1 ≤ i ≤ j ≤ n\n:LS: PM[i, j] = s(i, j) PM[i + (j -1) * (2n - j) ÷ 2] for 1 ≤ j ≤ i ≤ n\n\nwhere n is the side dimension of the packed matrix PM, s(i, i) = 1, and s(i, j) = inv(sqrt(2)) for i ≠ j.\n\nwarning: Warning\nThe SPMatrix can be effciently broadcast to other matrices, which works on the vector representation. It can also receive values from generic matrices by copyto! or broadcasting. Using it in a mixed chain of broadcastings of different type is not implemented and will potentially lead to logical errors (in the sense that the types will not match) or even segfaults (as the correct index mapping is not implemented).\n\n\n\n\n\n","category":"type"},{"location":"reference.html#Creating-an-SPMatrix","page":"Reference","title":"Creating an SPMatrix","text":"","category":"section"},{"location":"reference.html#StandardPacked.SPMatrix-Union{Tuple{R}, Tuple{Integer, AbstractVector{R}, Symbol}} where R","page":"Reference","title":"StandardPacked.SPMatrix","text":"SPMatrix(dim::Integer, data::AbstractVector{R}, type::Symbol=:U)\n\nCreates a packed matrix from already existing vectorized data. type must be one of :U, :L, :US, or :LS.\n\n\n\n\n\n","category":"method"},{"location":"reference.html#StandardPacked.SPMatrix-Union{Tuple{R}, Tuple{UndefInitializer, Integer, Symbol}} where R","page":"Reference","title":"StandardPacked.SPMatrix","text":"SPMatrix{R}(undef, dim, type::Symbol=:U)\n\nCreates a packed matrix with undefined data. type must be one of :U, :L, :US, or :LS.\n\n\n\n\n\n","category":"method"},{"location":"reference.html#StandardPacked.SPMatrix-Union{Tuple{LinearAlgebra.Symmetric{R, <:AbstractMatrix{R}}}, Tuple{R}} where R","page":"Reference","title":"StandardPacked.SPMatrix","text":"SPMatrix(A::Union{<:Hermitian,<:Symmetric})\n\nConstruct a packed matrix from a Hermitian or symmetric wrapper of any other matrix. Note that in case a symmetric wrapper is used, the element type must be invariant under conjugation (but this is not checked)!\n\n\n\n\n\n","category":"method"},{"location":"reference.html#Formats-of-an-SPMatrix","page":"Reference","title":"Formats of an SPMatrix","text":"","category":"section"},{"location":"reference.html#StandardPacked.SPMatrixUpper","page":"Reference","title":"StandardPacked.SPMatrixUpper","text":"SPMatrixUpper{R,V}\n\nThis is a union type for scaled and unscaled packed matrices with upper triangular storage.\n\n\n\n\n\n","category":"type"},{"location":"reference.html#StandardPacked.SPMatrixLower","page":"Reference","title":"StandardPacked.SPMatrixLower","text":"SPMatrixLower{R,V}\n\nThis is a union type for scaled and unscaled packed matrices with lower triangular storage.\n\n\n\n\n\n","category":"type"},{"location":"reference.html#StandardPacked.SPMatrixUnscaled","page":"Reference","title":"StandardPacked.SPMatrixUnscaled","text":"SPMatrixUnscaled{R,V}\n\nThis is a union type for unscaled packed matrices with upper or lower triangular storage.\n\n\n\n\n\n","category":"type"},{"location":"reference.html#StandardPacked.SPMatrixScaled","page":"Reference","title":"StandardPacked.SPMatrixScaled","text":"SPMatrixScaled{R,V}\n\nThis is a union type for scaled packed matrices with upper or lower triangular storage.\n\n\n\n\n\n","category":"type"},{"location":"reference.html#StandardPacked.packed_isupper","page":"Reference","title":"StandardPacked.packed_isupper","text":"packed_isupper(::SPMatrix)\npacked_isupper(::Type{<:SPMatrix})\n\nReturns true iff the given packed matrix has upper triangular storage.\n\nSee also packed_islower, packed_isscaled.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#StandardPacked.packed_islower","page":"Reference","title":"StandardPacked.packed_islower","text":"packed_islower(::SPMatrix)\n\nReturns true iff the given packed matrix has lower triangular storage.\n\nSee also packed_isupper, packed_isscaled.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#StandardPacked.packed_isscaled","page":"Reference","title":"StandardPacked.packed_isscaled","text":"packed_isscaled(::SPMatrix)\n\nReturns true iff the given packed matrix has scaled storage, i.e., if the off-diagonal elements are internally stored with a scaling of sqrt2.\n\nSee also packed_isupper, packed_islower.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#StandardPacked.packed_scale!","page":"Reference","title":"StandardPacked.packed_scale!","text":"packed_scale!(P::SPMatrix)\n\nEnsures that P is a scaled packed matrix by multiplying off-diagonals by sqrt2 if necessary. Returns a scaled packed matrix. P itself should not be referenced any more, only the result of this function.\n\nSee also packed_unscale!.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#StandardPacked.packed_unscale!","page":"Reference","title":"StandardPacked.packed_unscale!","text":"packed_unscale!(P::SPMatrix)\n\nEnsures that P is an unscaled packed matrix by dividing off-diagonals by sqrt2 if necessary. Returns an unscaled packed matrix. P itself should not be referenced any more, only the result of this function.\n\nSee also packed_scale!.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#Accessing-the-data","page":"Reference","title":"Accessing the data","text":"","category":"section"},{"location":"reference.html#Base.getindex","page":"Reference","title":"Base.getindex","text":"P[idx]\n\nReturns the value that is stored at the position idx in the vectorized (possibly scaled) representation of P.\n\n\n\n\n\nP[row, col]\n\nReturns the value that is stored in the given row and column of P. This corresponds to the value in the matrix, so even if P is of a scaled type, this does not affect the result.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#Base.setindex!","page":"Reference","title":"Base.setindex!","text":"P[idx] = X\n\nSets the value that is stored at the position idx in the vectorized (possibly scaled) representation of P.\n\n\n\n\n\nP[row, col] = X\n\nSets the value that is stored in the given row and column of P. This corresponds to the value in the matrix, so if P is of a scaled type, X will internally be multiplied by sqrt2.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#Base.vec-Tuple{SPMatrix}","page":"Reference","title":"Base.vec","text":"vec(P::SPMatrix)\n\nReturns the vectorized data associated with P. Note that this returns the actual vector, not a copy.\n\n\n\n\n\n","category":"method"},{"location":"reference.html#Base.Matrix-Union{Tuple{SPMatrixUnscaled{R}}, Tuple{R}} where R","page":"Reference","title":"Base.Matrix","text":"Matrix{R}(P::SPMatrix{R}, viewtype=R isa Complex ? Hermitian : Symmetric) where {R}\n\nConstruct a dense matrix from a packed matrix. The parameter symmetric determines which kind of view is returned. Use convert(Matrix{R}, SPMatrix{R}) to return the matrix itself the opposite triangle explicitly filled.\n\n\n\n\n\n","category":"method"},{"location":"reference.html#StandardPacked.packedsize","page":"Reference","title":"StandardPacked.packedsize","text":"packedsize(dim::Integer)\npackedsize(A::AbstractMatrix)\n\nCalculates the number of unique entries in a symmetric matrix A with side dimension dim, fracmathitdim(mathitdim +1)2.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#StandardPacked.packedside","page":"Reference","title":"StandardPacked.packedside","text":"packedside(fullsize::Integer)\npackedside(AP::AbstractVector)\npackedside(P::SPMatrix)\n\nCalculates the side dimension of a vector AP of size fullside representing a symmetric packed matrix, fracsqrt8mathitfullsize -12.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#Diagonal-and-off-diagonal-elements","page":"Reference","title":"Diagonal and off-diagonal elements","text":"","category":"section"},{"location":"reference.html#StandardPacked.SPDiagonalIterator","page":"Reference","title":"StandardPacked.SPDiagonalIterator","text":"SPDiagonalIterator(P::SPMatrix, k=0)\nSPDiagonalIterator(fmt::Symbol, dim, k=0)\n\nCreates an iterator that returns the linear indices for iterating through the kth diagonal of a packed matrix.\n\n\n\n\n\n","category":"type"},{"location":"reference.html#StandardPacked.rmul_diags!","page":"Reference","title":"StandardPacked.rmul_diags!","text":"rmul_diags!(P::SPMatrix, factor)\n\nRight-multiplies all diagonal entries in P by factor. Returns P.\n\nSee also lmul_diags!, rmul_offdiags!, lmul_offdiags!.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#StandardPacked.rmul_offdiags!","page":"Reference","title":"StandardPacked.rmul_offdiags!","text":"rmul_offdiags!(P::SPMatrix, factor)\n\nRight-multiplies all off-diagonal entries in P by factor. Returns P.\n\nSee also rmul_diags!, lmul_diags!, lmul_offdiags!.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#StandardPacked.lmul_diags!","page":"Reference","title":"StandardPacked.lmul_diags!","text":"lmul_diags!(factor, P::SPMatrix)\n\nLeft-multiplies all diagonal entries in P by factor. Returns P.\n\nSee also rmul_diags!, rmul_offdiags!, lmul_offdiags!.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#StandardPacked.lmul_offdiags!","page":"Reference","title":"StandardPacked.lmul_offdiags!","text":"lmul_offdiags!(factor, P::SPMatrix)\n\nLeft-multiplies all diagonal entries in P by factor. Returns P.\n\nSee also rmul_diags!, rmul_offdiags!, lmul_diags!.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#Extensions-in-LinearAlgebra","page":"Reference","title":"Extensions in LinearAlgebra","text":"","category":"section"},{"location":"reference.html","page":"Reference","title":"Reference","text":"This section documents functions for which the interface provided by LinearAlgebra has been extended to cover the SPMatrix type. However, since SPMatrix is an AbstractMatrix, many more helper and convenience functions are actually available that will (hopefully) fall back to the efficient implementations documented here.","category":"page"},{"location":"reference.html#LinearAlgebra.dot","page":"Reference","title":"LinearAlgebra.dot","text":"dot(::SPMatrix, ::SPMatrix)\n\nGives the scalar product between two packed matrices, which corresponds to the Frobenius/Hilbert-Schmidt scalar product for matrices. This is fastest for scaled matrices.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.axpy!","page":"Reference","title":"LinearAlgebra.axpy!","text":"axpy!(α, x::Union{<:SPMatrix,<:AbstractVector},\n    y::Union{<:SPMatrix,<:AbstractVector})\n\nOverwrite y with x * α + y and return y, where both x and y are interpreted as their corresponding vectorizations.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.axpby!","page":"Reference","title":"LinearAlgebra.axpby!","text":"axpby!(α, x::Union{<:SPMatrix,<:AbstractVector}, β,\n    y::Union{<:SPMatrix,<:AbstractVector})\n\nOverwrite y with x * α + y * β and return y, where both x and y are interpreted as their corresponding vectorizations.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.factorize","page":"Reference","title":"LinearAlgebra.factorize","text":"factorize(A::SPMatrix)\n\nCompute a Bunch-Kaufman factorization of A.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.cholesky","page":"Reference","title":"LinearAlgebra.cholesky","text":"cholesky(P::SPMatrix, NoPivot(); shift=0, check=true) -> Cholesky\n\nCompute the Cholesky factorization of a packed positive definite matrix P and return a Cholesky factorization.\n\nThe triangular Cholesky factor can be obtained from the factorization F via F.L and F.U, where P ≈ F.U' * F.U ≈ F.L * F.L'.\n\nThe following functions are available for Cholesky objects from packed matrices: size, \\, inv, det, logdet, isposdef.\n\nWhen check = true, an error is thrown if the decomposition fails. When check = false, responsibility for checking the decomposition's validity (via issuccess) lies with the user.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.cholesky!","page":"Reference","title":"LinearAlgebra.cholesky!","text":"cholesky!(P::SPMatrix, NoPivot(); shift=0, check=true) -> Cholesky\n\nThe same as cholesky, but saves space by overwriting the input P, instead of creating a copy.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.bunchkaufman","page":"Reference","title":"LinearAlgebra.bunchkaufman","text":"bunchkaufman(P::SPMatrix, ipiv=missing; check = true) -> S::BunchKaufman\n\nCompute the Bunch-Kaufman factorization of a packed matrix P P'*U*D*U'*P or P'*L*D*L'*P, depending on which triangle is stored in P, and return a BunchKaufman object.\n\nIterating the decomposition produces the components S.D, S.U or S.L as appropriate given S.uplo, and S.p.\n\nWhen check = true, an error is thrown if the decomposition fails. When check = false, responsibility for checking the decomposition's validity (via issuccess) lies with the user.\n\nThe following functions are available for BunchKaufman objects: size, \\, inv, getindex.\n\nThe pivoting vector ipiv may be passed beforehand to save allocations.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.bunchkaufman!","page":"Reference","title":"LinearAlgebra.bunchkaufman!","text":"bunchkaufman!(P::SPMatrix, ipiv=missing; check = true) -> S::BunchKaufman\n\nThe same as bunchkaufman, but saves space by overwriting the input P, instead of creating a copy.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.eigvals","page":"Reference","title":"LinearAlgebra.eigvals","text":"eigvals(P::SPMatrix, args...)\n\nReturn the eigenvalues of P.\n\nThis function calls spevd! and will forward all additional arguments. However, consider using eigvals! for a non-allocationg version.\n\n\n\n\n\neigvals(P::SPMatrix, vl::Real, vu::Real, args...)\n\nReturn the eigenvalues of P. It is possible to calculate only a subset of the eigenvalues by specifying a pair vl and vu for the lower and upper boundaries of the eigenvalues.\n\nThis function calls spevx! and will forward all additional arguments. However, consider using eigvals! for a non-allocationg version.\n\n\n\n\n\neigvals(P::SPMatrix, range::UnitRange, args...)\n\nReturn the eigenvalues of P, overwriting P in the progress. It is possible to calculate only a subset of the eigenvalues by specifying a UnitRange range covering indices of the sorted eigenvalues, e.g. the 2nd to 8th eigenvalues.\n\nThis function calls spevx! and will forward all additional arguments. However, consider using eigvals! for a non-allocationg version.\n\n\n\n\n\neigvals(AP::SPMatrix, BP::SPMatrix, args...)\n\nCompute the generalized eigenvalues of AP and BP.\n\nSee also eigen.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.eigvals!","page":"Reference","title":"LinearAlgebra.eigvals!","text":"eigvals!(P::SPMatrix, args...)\neigvals!(P::SPMatrix, vl::Real, vu::Real, args...)\neigvals!(P::SPMatrix, range::UnitRange, args...)\n\nThe same as eigvals, but saves space by overwriting the input P, instead of creating a copy.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.eigmax","page":"Reference","title":"LinearAlgebra.eigmax","text":"eigmax(P::SPMatrix, args...)\n\nReturn the largest eigenvalue of P.\n\nSee also eigmax!, eigvals.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#StandardPacked.eigmax!","page":"Reference","title":"StandardPacked.eigmax!","text":"eigmax!(P::SPMatrix, args...)\n\nReturn the largest eigenvalue of P, overwriting P in the progress.\n\nSee also eigvals!.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.eigmin","page":"Reference","title":"LinearAlgebra.eigmin","text":"eigmin(P::SPMatrix, args...)\n\nReturn the smallest eigenvalue of P\n\nSee also eigmin!, eigvals.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#StandardPacked.eigmin!","page":"Reference","title":"StandardPacked.eigmin!","text":"eigmin!(P::SPMatrix, args...)\n\nReturn the smallest eigenvalue of P, overwriting P in the progress.\n\nSee also eigvals!.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.eigvecs","page":"Reference","title":"LinearAlgebra.eigvecs","text":"eigvecs(P::SPMatrix, args...)\n\nReturn a matrix M whose columns are the eigenvectors of P. (The kth eigenvector can be obtained from the slice M[:, k].)\n\nSee also eigen.\n\n\n\n\n\neigvecs(A::SPMatrix, B::SPMatrix, args...)\n\nReturn a matrix M whose columns are the generalized eigenvectors of A and B. (The kth eigenvector can be obtained from the slice M[:, k].)\n\nSee also eigen.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#StandardPacked.eigvecs!","page":"Reference","title":"StandardPacked.eigvecs!","text":"eigvecs!(P::SPMatrix, args...)\neigvecs(A::SPMatrix, B::SPMatrix, args...)\n\nThe same as eigvecs, but saves space by overwriting the input P (or A and B), instead of creating a copy.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.eigen","page":"Reference","title":"LinearAlgebra.eigen","text":"eigen(P::SPMatrix, args...) -> Eigen\n\nCompute the eigenvalue decomposition of P, returning an Eigen factorization object F which contains the eigenvalues in F.values and the eigenvectors in the columns of the matrix F.vectors. (The kth eigenvector can be obtained from the slice F.vectors[:, k].)\n\nThis function calls spevd! and will forward all arguments. However, consider using eigen! for a non-allocating version.\n\n\n\n\n\neigen(A::SPMatrix, B::SPMatrix, args...) -> GeneralizedEigen\n\nCompute the generalized eigenvalue decomposition of A and B, returning a GeneralizedEigen factorization object F which contains the generalized eigenvalues in F.values and the generalized eigenvectors in the columns of the matrix F.vectors. (The kth generalized eigenvector can be obtained from the slice F.vectors[:, k].)\n\nThis function calls spgvd! and will forward all arguments. However, consider using eigen! for a non-allocating version.\n\n\n\n\n\neigen(P::SPMatrix, irange::UnitRange, args...)\n\nCompute the eigenvalue decomposition of P, returning an Eigen factorization object F which contains the eigenvalues in F.values and the eigenvectors in the columns of the matrix F.vectors. (The kth eigenvector can be obtained from the slice F.vectors[:, k].)\n\nThe UnitRange irange specifies indices of the sorted eigenvalues to search for.\n\nThis function calls spevx! and will forward all arguments. However, consider using eigen! for a non-allocating version.\n\n\n\n\n\neigen(P::SPMatrix, vl::Real, vu::Real, args...)\n\nCompute the eigenvalue decomposition of P, returning an Eigen factorization object F which contains the eigenvalues in F.values and the eigenvectors in the columns of the matrix F.vectors. (The kth eigenvector can be obtained from the slice F.vectors[:, k].)\n\nvl is the lower bound of the window of eigenvalues to search for, and vu is the upper bound.\n\nThis function calls spevx! and will forward all arguments. However, consider using eigen! for a     non-allocating version.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.eigen!","page":"Reference","title":"LinearAlgebra.eigen!","text":"eigen!(P::SPMatrix, args...)\neigen!(A::SPMatrix, B::SPMatrix, args...)\n\nSame as eigen, but saves space by overwriting the input A (and B) instead of creating a copy.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.diagind","page":"Reference","title":"LinearAlgebra.diagind","text":"diagind(P::SPMatrix, k::Integer=0)\n\nA vector containing the indices of the kthe diagonal of the packed matrix P.\n\nSee also: diag, SPDiagonalIterator.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.diag","page":"Reference","title":"LinearAlgebra.diag","text":"diag(P::SPMatrix, k::Integer=0)\n\nThe kth diagonal of a packed matrix, as a vector.\n\nSee also: diagind, SPDiagonalIterator.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.norm","page":"Reference","title":"LinearAlgebra.norm","text":"norm(P::SPMatrix, p::Real=2)\n\nFor any packed matrix P, compute the p-norm as if P was interpreted as a full vector (containing the off-diagonals twice without scaling).\n\nThe p-norm is defined as\n\n    lVert PrVert_p = Biggl( sum_i j = 1^n lvert P_i jrvert^p Biggr)^1p\n\nwith P_i j the entries of P, lvert P_i jrvert the norm of P_i j, and n its side dimension.\n\np can assume any numeric value (even though not all values produce a mathematically valid vector norm). In particular, norm(P, Inf) returns the largest value in abs.(P), whereas norm(P, -Inf) returns the smallest. If p=2, then this is equivalent to the Frobenius norm.\n\nThe second argument p is not necessarily a part of the interface for norm, i.e. a custom type may only implement norm(P) without second argument.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.tr","page":"Reference","title":"LinearAlgebra.tr","text":"tr(P::SPMatrix)\n\nMatrix trace. Sums the diagonal elements of P.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.isposdef","page":"Reference","title":"LinearAlgebra.isposdef","text":"isposdef(P::SPMatrix, tol=0)\n\nTest whether a matrix is positive definite by trying to perform a Cholesky factorization of P.\n\nSee also isposdef!, cholesky.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.isposdef!","page":"Reference","title":"LinearAlgebra.isposdef!","text":"isposdef!(P::SPMatrix, tol=0)\n\nTest whether a matrix is positive definite by trying to perform a Cholesky factorization of P, overwriting P in the process. See also isposdef.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#Base.transpose","page":"Reference","title":"Base.transpose","text":"transpose(P::SPMatrix{<:Real})\n\nIdentity operation for real-valued packed matrices.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#Base.adjoint","page":"Reference","title":"Base.adjoint","text":"P'\nadjoint(P::SPMatrix)\n\nIdentity operation for packed matrices\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.checksquare","page":"Reference","title":"LinearAlgebra.checksquare","text":"checksquare(P::SPMatrix)\n\nReturns the side dimension of P.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#Low-level-matrix-operations","page":"Reference","title":"Low-level matrix operations","text":"","category":"section"},{"location":"reference.html#LinearAlgebra.mul!","page":"Reference","title":"LinearAlgebra.mul!","text":"mul!(::SPMatrix, B::AbstractMatrix, ::AbstractVector, α, β)\nmul!(::SPMatrix, B::AbstractMatrix, ::SPMatrix, α, β)\nmul!(::AbstractVector, B::AbstractMatrix, ::SPMatrix, α, β)\n\nCombined inplace matrix-vector multiply-add A B α + C β. The result is stored in C by overwriting it. Note that C must not be aliased with either A or B. This method will automatically interpret all SPMatrix arguments as their (scaled) vectorizations (so this is simply an alias to calling the standard mul! method on the vec of the packed matrices).\n\nNote that B must not be a packed matrix.\n\n\n\n\n\nmul!(C::AbstractVector, A::SPMatrixUnscaled, B::AbstractVector, α, β)\n\nCombined inplace matrix-vector multiply-add A B α + C β. The result is stored in C by overwriting it. Note that C must not be aliased with either A or B. This method requires an unscaled packed matrix and only works on native floating point types supported by BLAS.\n\nSee also spmv!, hpmv!.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.lmul!","page":"Reference","title":"LinearAlgebra.lmul!","text":"lmul!(a::Number, P::SPMatrix)\n\nScale a packed matrix P by a scalar a overwriting P in-place. Use rmul! to multiply scalar from right. The scaling operation respects the semantics of the multiplication * between a and an element of P. In particular, this also applies to multiplication involving non-finite numbers such as NaN and ±Inf.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.rmul!","page":"Reference","title":"LinearAlgebra.rmul!","text":"rmul!(P::SPMatrix, b::Number)\n\nScale a packed matrix P by a scalar b overwriting P in-place. Use lmul! to multiply scalar from left. The scaling operation respects the semantics of the multiplication * between an element of P and b. In particular, this also applies to multiplication involving non-finite numbers such as NaN and ±Inf.\n\n\n\n\n\n","category":"function"},{"location":"reference.html#LinearAlgebra.ldiv!","page":"Reference","title":"LinearAlgebra.ldiv!","text":"ldiv!(P, B)\n\nCompute P \\ B in-place and overwriting B to store the result.\n\nThe argument P should not be a matrix. Rather, instead of matrices it should be a factorization object (e.g. produced by cholesky or bunchkaufman from a SPMatrix). The reason for this is that factorization itself is both expensive and typically allocates memory (although it can also be done in-place via, e.g., cholesky!), and performance-critical situations requiring ldiv! usually also require fine-grained control over the factorization of P.\n\n\n\n\n\n","category":"function"},{"location":"index.html#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"StandardPacked is a Julia package that wraps functions for storing symmetric matrices in their standard packed form, i.e., column-wise stacked upper or lower triangles. It also provides bindings for the corresponding LAPACK functions, which allow things such as eigendecompositions. Note that typically, the packed form requires a bit longer calculation times and is slightly more imprecise than the dense form; however, it requires less storage.","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Additionally, this package also provides the scaled form of the packed storage, in which off-diagonal elements are scaled by a factor of sqrt2. This kind of format is very often used as input to semidefinite solvers, as it has the advantage that the scalar product between the vectorizations of two packed matrices is the same as the Hilbert-Schmidt/Frobenius scalar product between the actual matrices.","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Note that neither of those formats correspond to the rectangular full packed format. The latter has the same favorable scaling with respect to memory, but additionally a better layout for some linear algebra routines, making it almost as fast as the dense format. However, index access is a bit weird there and it is not in wide use; furthermore, there are far fewer LAPACK functions working with RFP. Consider RectangularFullPacked.jl instead.","category":"page"}]
}
